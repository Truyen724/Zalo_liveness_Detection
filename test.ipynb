{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import cv2\n",
    "import os\n",
    "import time \n",
    "import numpy as np\n",
    "from align_faces import warp_and_crop_face, get_reference_facial_points\n",
    "from mtcnn.detector import MtcnnDetector\n",
    "detector = MtcnnDetector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_detect(image):\n",
    "    (h,w) = image.shape[:2]\n",
    "    boxes, facial5points = detector.detect_faces(image)\n",
    "    face = np.zeros(shape =(256,256,3))\n",
    "    if(len(boxes)!=0):\n",
    "        for box in boxes:\n",
    "            (startX,startY,endX,endY)=box[:4].astype('int')\n",
    "            #ensure the bounding boxes fall within the dimensions of the frame\n",
    "            (startX,startY)=(max(0,startX),max(0,startY))\n",
    "            (endX,endY)=(min(w-1,endX), min(h-1,endY))\n",
    "            #extract the face ROI, convert it from BGR to RGB channel, resize it to 224,224 and preprocess it\n",
    "            c=cv2.resize(image[startY:endY, startX:endX],(256,256))\n",
    "            face = c\n",
    "            color = (255,0,0)\n",
    "            cv2.rectangle(image,(startX,startY),(endX,endY),color,2)\n",
    "    return image, face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "len_of_lst = 128 + 128\n",
    "print(len_of_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "face = np.zeros(shape =(256,256,3))\n",
    "print(face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_lst = 192\n",
    "def PlayCamera(id):    \n",
    "    num_of_face = 0\n",
    "    video_capture = cv2.VideoCapture(id)\n",
    "    face = None\n",
    "    list_face = np.zeros(shape = (len_of_lst, 256, 256,3), dtype=np.uint8)\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        img, face = mask_detect(frame)\n",
    "        list_face[num_of_face] = face\n",
    "        num_of_face +=1      \n",
    "        # cv2.imshow(\"img\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return list_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "id = \"../train_avi/videos/1.mp4\"\n",
    "lsst, lst = PlayCamera(id)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",lsst[1])\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.uint8'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(lst[0][0,0,0]))\n",
    "print(type(lsst[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = \"../train/videos/1.mp4\"\n",
    "# video_capture = cv2.VideoCapture(id)\n",
    "# num = 0\n",
    "# while True:\n",
    "    \n",
    "#     ret, frame = video_capture.read()\n",
    "#     num += 1\n",
    "#     img, face = mask_detect(frame)\n",
    "\n",
    "#     cv2.imshow('{}'.format(id), img)        \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        \n",
    "\n",
    "#         break\n",
    "    \n",
    "# print(num)\n",
    "# PlayCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to AVI\n",
    "# import imageio\n",
    "# src_dir = \"../train/videos/\"\n",
    "# dest_dir = \"../train_avi/videos/\"\n",
    "# lstmp4 = os.listdir(src_dir)\n",
    "\n",
    "# for file in lstmp4:\n",
    "#     scr = src_dir+file\n",
    "    \n",
    "#     des = dest_dir + file\n",
    "    \n",
    "#     reader = imageio.get_reader(scr)\n",
    "#     fps = reader.get_meta_data()['fps']\n",
    "#     writer = imageio.get_writer(des, fps=fps)\n",
    "\n",
    "#     for im in reader:\n",
    "#         writer.append_data(im[:, :, :])\n",
    "#     writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"Truyen_small.png\")\n",
    "img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(img1,100,200)\n",
    "img_zero = np.zeros(shape =(img1.shape[0],img1.shape[1],3))\n",
    "x = cosine_similarity(np.array([lsst[1].reshape(-1)]), np.array([lsst[59].reshape(-1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90213471]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 49 34]\n",
      "[22. 49. 34.]\n"
     ]
    }
   ],
   "source": [
    "print(lst[0][0,1])\n",
    "print(lsst[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 443, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"x\",edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
